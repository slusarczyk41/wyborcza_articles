{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from scrap_article_new_tab import scrap_article\n",
    "# from threading import Thread\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta as td\n",
    "from os import makedirs\n",
    "from os.path import exists\n",
    "from time import sleep\n",
    "from json import loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = dt.now()\n",
    "year = now.year\n",
    "month = now.month\n",
    "day = now.day\n",
    "ts = str(int(round(now.timestamp())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "chrome = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrome = webdriver.Chrome()#chrome = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome.get(url = 'http://wyborcza.pl/0,75248.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = []\n",
    "for entry in chrome\\\n",
    "    .find_element_by_xpath('//*[@id=\"pagetype_index\"]/section[5]/div/main/div/div[2]/div/div[2]/ul')\\\n",
    "    .find_elements_by_class_name('entry'):\n",
    "    entryContainer = {}\n",
    "    \n",
    "    entryContainer['author'] = entry.find_element_by_class_name('author').text.replace('|', '').strip()\n",
    "    header = entry.find_element_by_tag_name('h3')\\\n",
    "                .find_element_by_tag_name('a')\n",
    "    entryContainer['title'] = header.get_attribute('title')\n",
    "    entryContainer['url'] = header.get_attribute('href')\n",
    "    entryContainer['article_id'] = entryContainer['url'].split('/')[-1].split(',')[2]\n",
    "    entryContainer['lead'] = entry.find_element_by_tag_name('p').text\n",
    "    entryContainer['date'] = entry.find_element_by_class_name('when').text\n",
    "    \n",
    "    entries.append(entryContainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to click rodo (first click opens sometimes an ad)\n",
    "for i in range(3):\n",
    "    try:\n",
    "        sleep(3)\n",
    "        chrome.find_element_by_xpath('//*[@id=\"rodoNotificationWrapper\"]/div[1]/div/p[2]')\\\n",
    "            .click()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close new window\n",
    "try:\n",
    "    chrome.switch_to.window(chrome.window_handles[1])\n",
    "    chrome.close()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapped_articles = pd.DataFrame(entries)\n",
    "scrapped_articles['is_new'] = True\n",
    "scrapped_articles['content'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapped_articles.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_articles = pd.read_csv('articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#existing_articles.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scrapped_articles[~scrapped_articles['article_id'].isin(existing_articles['article_id'].unique())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(existing_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_articles = existing_articles.append(scrapped_articles, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles = combined_articles.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles['date'] = pd.to_datetime(all_articles['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_to_drop = all_articles[\n",
    "    all_articles['date'] <= dt.now() - td(days=7)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if articles_to_drop.empty == True:\n",
    "    pass\n",
    "else:\n",
    "    existing_articles_to_drop = pd.read_csv('old_articles.csv')\n",
    "    existing_articles_to_drop = existing_articles_to_drop.append(articles_to_drop)\n",
    "    # backup file\n",
    "    filename_to_save = 'data/backup/old/{}/{}/{}/'.format(\n",
    "        year, month, day\n",
    "    )\n",
    "    if not exists(filename_to_save):\n",
    "        makedirs(filename_to_save)\n",
    "    existing_articles_to_drop.to_csv(filename_to_save+str(ts)+'.csv', index=False)\n",
    "    # save used in script file\n",
    "    existing_articles_to_drop.to_csv('data/old_articles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_to_continue = all_articles[\n",
    "    all_articles['date'] > dt.now() - td(days=7)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  --------------------- TMP ---------------------\n",
    "articles_to_continue['is_new'] = True\n",
    "articles_to_continue['last_date'] = dt.now() - td(minutes=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#articles_to_continue.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_date(last_date, pub_date):\n",
    "    hours_since_pub = (dt.now() - pub_date).total_seconds() / 60 / 60\n",
    "    if hours_since_pub < 2:\n",
    "        interval = 5 # in minutes\n",
    "    elif hours_since_pub < 5:\n",
    "        interval = 10\n",
    "    elif hours_since_pub < 10:\n",
    "        interval = 20\n",
    "    else:\n",
    "        interval = 30\n",
    "    \n",
    "    if dt.now() - td(minutes=interval) < last_date:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_date(pub_date):\n",
    "    days_since_pub = (dt.now() - pub_date).total_seconds() / 60 / 60 / 24\n",
    "    if days_since_pub > 5:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_to_scrap = articles_to_continue[articles_to_continue['date'] < dt.now() - td(days=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_to_continue[articles_to_continue['date'] >= dt.now() - td(days=5)].to_csv('articles.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_list = articles_to_scrap.to_dict('rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TMP\n",
    "#options = webdriver.ChromeOptions()\n",
    "#options.add_argument(\"--disable-popup-blocking\")\n",
    "#chrome = webdriver.Chrome()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chrome.execute_script(\"window.close();\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chrome.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrome.execute_script(\"window.open('{}','_blank');\".format(article['url']))\n",
    "# for i in range(10):\n",
    "#     if chrome.execute_script(\"return document.readyState\") != 'complete':\n",
    "#         print('not ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chrome.switch_to.window(chrome.window_handles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome.switch_to.window(chrome.window_handles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = []\n",
    "first = True\n",
    "if len(articles_list) != 0:\n",
    "    for article in articles_list:\n",
    "        article_id = article['url'].split('/')[-1].split(',')[2]\n",
    "        chrome.execute_script(\"window.open('{}','_blank');\".format(article['url']))\n",
    "        chrome.close()\n",
    "        chrome.switch_to.window(chrome.window_handles[0])\n",
    "        sleep(7)\n",
    "\n",
    "\n",
    "\n",
    "        if check_date(article['date']):\n",
    "            if article['is_new']:\n",
    "                a = loads(scrap_article(chrome=chrome, first_time=True))\n",
    "                article['article_id'] = article_id\n",
    "                article['content'] = a['content']\n",
    "                article['division'] = a['division']\n",
    "                article['highlight'] = a['highlight']\n",
    "                article['media_type'] = a['media_type']\n",
    "                article['media_src'] = a['media_src']\n",
    "                article['media_desc'] = a['media_desc']\n",
    "                article['is_new'] = False\n",
    "                with open('data/comments/'+article_id, 'w') as f:\n",
    "                    f.write(str({'row': {\n",
    "                       'comments': a['comments'],\n",
    "                       'timestamp': dt.timestamp(dt.now())\n",
    "                       }\n",
    "                    }))\n",
    "        container.append(article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(articles_list) != 0:\n",
    "    articles_updated = pd.DataFrame(container)\n",
    "    if 'Unnamed: 0' in articles_updated.columns:\n",
    "        articles_updated = articles_updated.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "    filename_to_save = 'data/backup/scrapped/{}/{}/{}'.format(\n",
    "            year, month, day, ts\n",
    "        )\n",
    "    if not exists(filename_to_save):\n",
    "        makedirs(filename_to_save)\n",
    "\n",
    "    articles_updated.to_csv('data/backup/scrapped/{}/{}/{}/{}.csv'.format(\n",
    "            year, month, day, ts\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
