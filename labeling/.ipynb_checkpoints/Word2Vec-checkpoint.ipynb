{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "https://towardsdatascience.com/learn-word2vec-by-implementing-it-in-tensorflow-45641adaf2ac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab words I picked to represent emotions\n",
    "from emotions import all_flag_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed_comments_1.csv', nrows = 1000)[['words']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only care about comments with flag words\n",
    "df = df[df['words'].str.contains(r'|'.join(all_flag_words))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate number of occurences for each word present in dataset\n",
    "words_dict_counter = {}\n",
    "step = 10\n",
    "\n",
    "for comment in df['words']:\n",
    "    listed_comment = eval(comment)\n",
    "    contains_word_flag = False\n",
    "\n",
    "    for i, word in enumerate(listed_comment):\n",
    "\n",
    "        if word not in words_dict_counter.keys():\n",
    "            words_dict_counter[word] = {}\n",
    "\n",
    "        if i-step < 0:\n",
    "            first_index = 0\n",
    "            to_delete = i\n",
    "        else:\n",
    "            first_index = i-step\n",
    "            to_delete = step\n",
    "\n",
    "        corresponding_words = listed_comment[first_index: i+step+1]\n",
    "        del corresponding_words[to_delete]\n",
    "\n",
    "        for corresponding_word in corresponding_words:\n",
    "            if corresponding_word not in words_dict_counter[word].keys():\n",
    "                words_dict_counter[word][corresponding_word] = 1\n",
    "            else:\n",
    "                words_dict_counter[word][corresponding_word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data (pairs) preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to feed neural network (input: surrounding word, output: word \"in the middle\")\n",
    "pairs = []\n",
    "words = []\n",
    "for middle_word, proximity in words_dict_counter.items():\n",
    "    words.append(middle_word)\n",
    "    for proximity_word, num_of_occurences in proximity.items():\n",
    "        words.append(proximity_word)\n",
    "        for i in range(num_of_occurences):\n",
    "            pairs.append([middle_word, proximity_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(pairs) # to shuffle duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19366"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['refleksja', 'bienkowskiej'],\n",
       " ['wyborca', 'taka'],\n",
       " ['euro', 'wiemy'],\n",
       " ['zwykla', 'komuchom'],\n",
       " ['podjudic', 'wolnosc'],\n",
       " ['kilku', 'lodzia'],\n",
       " ['nedzne', 'ciesze'],\n",
       " ['rolnikow', 'pojecia'],\n",
       " ['kamili', 'zl'],\n",
       " ['mieszkanie', 'rdzennemu']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as stated in the article, it will be very usefull later\n",
    "word2int = {}\n",
    "int2word = {}\n",
    "for i,word in enumerate(list(set(words))):\n",
    "    word2int[word] = i\n",
    "    int2word[i] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1043"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique words should be equal to vector length\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change our data to format understandable by nn\n",
    "def to_one_hot(data_point_index, vocab_size):\n",
    "    temp = np.zeros(vocab_size)\n",
    "    temp[data_point_index] = 1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [] \n",
    "y_train = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in pairs:\n",
    "    x_train.append(to_one_hot(word2int[ pair[0] ], vocab_size))\n",
    "    y_train.append(to_one_hot(word2int[ pair[1] ], vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19366, 1043) (19366, 1043)\n"
     ]
    }
   ],
   "source": [
    "# So we have i training samples, and each one is a vector of length j\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, vocab_size))\n",
    "y_label = tf.placeholder(tf.float32, shape=(None, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jacek/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# The hidden layer of nn (our desired word2vec's)\n",
    "W1 = tf.Variable(tf.random_normal([vocab_size, EMBEDDING_DIM]))\n",
    "b1 = tf.Variable(tf.random_normal([EMBEDDING_DIM]))\n",
    "hidden_representation = tf.add(tf.matmul(x,W1), b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output layer\n",
    "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, vocab_size]))\n",
    "b2 = tf.Variable(tf.random_normal([vocab_size]))\n",
    "# about softmax: https://www.youtube.com/watch?v=mlaLLQofmR8\n",
    "prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_representation, W2), b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loss functions equastion is at 5:00 from the video above\n",
    "cross_entropy_loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jacek/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for _ in range(n_iters):\n",
    "    sess.run(train_step, feed_dict={x: x_train, y_label: y_train})\n",
    "    losses.append(sess.run(cross_entropy_loss, feed_dict={x: x_train, y_label: y_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'../processed_comments_1.csv' does not exist: b'../processed_comments_1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-dfe44cc97730>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mone_block_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-dfe44cc97730>\u001b[0m in \u001b[0;36mone_block_iter\u001b[0;34m(step)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mone_block_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../processed_comments_1.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'words'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'list'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'words'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'list'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../processed_comments_1.csv' does not exist: b'../processed_comments_1.csv'"
     ]
    }
   ],
   "source": [
    "def one_block_iter(step):\n",
    "    df = pd.read_csv('../processed_comments_1.csv', nrows = 1000)[['words']]\n",
    "    df['list'] = df['words'].str.strip('[]').str.split(',')\n",
    "    for word in df['list'].values:\n",
    "    \n",
    "    \n",
    "        return word\n",
    "    \n",
    "one_block_iter(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 16.66794319152832)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(losses)\n",
    "ax.set_ylim(ymin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to have proper word2vec we need to sum variables with biases\n",
    "vectors = sess.run(W1 + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.6619563 , -1.0549307 ,  2.6038985 ,  0.12125186,  0.83705056,\n",
       "       -1.5220432 ,  1.3179718 , -0.79900974,  0.38480353, -0.14116944],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do PCA on vactors so it will be possible to visualize them\n",
    "model = TSNE(n_components=2, random_state=0)\n",
    "np.set_printoptions(suppress=True)\n",
    "vectors = model.fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = max(vectors.T.max(), -vectors.T.min())\n",
    "fig, ax = plt.subplots(figsize = (20,20))\n",
    "ax.axis([-a, a, -a, a])\n",
    "for word in words:\n",
    "    if word in all_flag_words:\n",
    "        ax.annotate(word, (vectors[word2int[word]][0],vectors[word2int[word]][1] ), color = 'red')\n",
    "    else:\n",
    "        ax.annotate(word, (vectors[word2int[word]][0],vectors[word2int[word]][1] ))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also won't gave us anything usefull. Words around flag ones are not related, even the words like 'happy'(ciesze) and 'kill'(zabic) are close to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
